<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="UTF-8">
    <title>Handwritten Digit Recognition by Convolutional Neural Network</title>
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script type="text/javascript" src="mathutils.js"></script>
    <script type="text/javascript" src="mnist_digit_labels.js"></script>
    <script type="text/javascript" src="webcnn.js"></script>
    <script type="text/javascript" src="digitdemo.js"></script>
    <link href="digitdemo.css" rel="stylesheet"/>
</head>
<body>

<a target="_blank" href="https://github.com/diaphone/webcnn"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png"></a>

<div id="headerDiv"><a href="http://denseinl2.com">DenseInL2.com</a></div>

<div id="contentDiv">
<h1>Handwritten Digit Recognition by Convolutional Neural Network</h1>
<p>
    This is a demonstration of my <a target="_blank" href="https://github.com/diaphone/webcnn">JavaScript-based Convolutional Neural Network</a>.
    Draw a digit from 0 to 9
    in the left box, and the network will attempt to recognize it. The system evaluates your drawing after
    each stroke (mouse button up), so expect incorrect intermediate results if you draw your digit using
    more than one stroke. Because the pre-processing of your input records and scales strokes, rather than
    downsampling the canvas bitmap directly, building up a drawing from
    short dashes or dots may not give accurate classification.
    <p>
    The associated training page for this network is here: <a target="_blank" href="digittraining.html">digittraining.html</a>
</p>
</p>

<div id="recognizer">
    <div class="inlineDiv">
        <div id="drawingCanvasDiv"><canvas id="drawCanvas" width="300" height="300"></canvas></div>
        <button class="silverButton" onclick="buttonClick(2)" id="clearButton">Reset</button>
    </div>
    <div class="inlineDiv">
        <div id="guessNumberDiv"></div>
        <div>Confidence: <span id="confidence">0%</span></div>
    </div>

</div>
    <div style="text-align: center; font-size: 12px; padding: 8px 0px 0px 0px;">Note: This demo uses ES6 features and will not run in Safari 9.x. Try Chrome 52+, Firefox 50+.</div>
    <h2>But this has been done before...</h2>
    <p>
        Yes, well, sort of. It's a classic dataset now, and there are a couple of other JavaScript demos similar to this one on the web already,
        but what makes this one different is that I've coded the full training of the network, not merely the forward evaluation.
        Other online demos I've found that let you draw digits for recognition
        have only the forward implementation in JavaScript, and their network was trained externally in a commercial
        product like MATLAB or TensorFlow. <a target="_blank" href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html">Andrej Karpathy's ConvNetJS</a> is the only other complete JavaScript CNN implementation
        that I'm aware of. Because my motivation for doing this project is to learn about how these things
        work--at the most fundamental level--and because deriving and implementing
        the gradient descent training of the network is where the real math is, I decided not to cut any corners and to
        intentionally re-invent the wheel for my own understanding. You can see
        my somewhat crude training page here: <a target="_blank" href="digittraining.html">digittraining.html</a>
        This network instance has been trained on the MNIST set of 60,000 handwritten digit images, and scores
        approximately 98% accuracy on the associated set of 10,000 validation images.
    </p>
<h2>So, what is this doing?</h2>
<p>
    The images you draw in the box above are being fed into a <a target="_blank" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a> that I wrote
    in JavaScript/ES6 and trained on the <a target="_blank" href="http://yann.lecun.com/exdb/mnist/">MNIST dataset of handwritten digits</a>.
    The network consists of digital filters that start out initialized with random values in their
    kernels. The network &quot;learns&quot; to distinguish the features of digits by a negative feedback process known as
    <a target="_blank" href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a>. Labeled example
    digits are fed into the network, and any error in their classification is used to tune the network--making small adjustments to values in the
    filter kernels and to the weights of connections to the output layer--to produce a more accurate score. This
    is repeated for tens of thousands of example digit images, until the network has converged on a set of filters that can accurately
    differentiate between all 10 digits.
</p>

<h2>This network's architecture</h2>

    The network analyzing the digits consists of:
    <ul>
    <li>The input image pre-processor, which crops your drawing down to a 24x24 pixel input image, redrawing it
    with a thinner stroke if it does not fill the box</li>
    <li>A convolution layer with (10) 5x5x1 filter kernels, ReLU activation</li>
    <li>A modified<sup>1</sup> max pooling layer, 2x2 with strides of 2</li>
    <li>A convolution layer with (20) 5x5x10 filter kernels, ReLU activation</li>
    <li>A modified max pooling layer, 2x2 with strides of 2</li>
    <li>A fully-connected layer with 10 units with soft-max activation</li>
    </ul>

<p>
    During training of the network, I used a small amount of input image augmentation suggested by
    <a target="_blank" href="http://cs.stanford.edu/people/karpathy/">Andrej Karpathy</a> in the notes accompanying his MNIST example
    here: <a target="_blank" href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html">http://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html</a>
    A random 24x24 crop is taken from each of the 28x28 digit images. The network was trained using 2 passes of the dataset, a total
    of 120,000 impressions.

</p>
<div class="footnote"><sup>1</sup>I've implemented the max pool layers to backpropagate error evenly to all input pixels that attained the maximum during training, when there
    is more than one, rather than the more traditional approach of randomly selecting one when this occurs.</div>

</div>
<div id="footerDiv">
    Dense in L2 &centerdot; Adam Smith &copy;2017
</div>
<script>
	function updateSliderDisplay( id, value )
	{
		document.querySelector('#'+id).value = value;
	}
</script>
</body>
</html>